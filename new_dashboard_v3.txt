import boto3
import json
import logging

# Initialize AWS clients
dynamodb = boto3.client('dynamodb')
cloudwatch = boto3.client('cloudwatch')
logs_client = boto3.client('logs')

# Setup logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Function to get all DynamoDB entries with proper error handling
def get_all_dynamodb_entries():
    try:
        response = dynamodb.scan(TableName='ResourceMetrics')
        entries = response['Items']
        logger.info(f"Fetched {len(entries)} entries from DynamoDB.")
        return entries
    except Exception as e:
        logger.error(f"Error fetching entries from DynamoDB: {e}")
        return []

# Function to look up log groups with pagination and filtering within the /aws/ prefix
def lookup_log_groups(resource_name):
    try:
        log_group_prefix = "/aws/"
        found_log_groups = []
        next_token = None

        # Paginate through log groups to find all matches
        while True:
            if next_token:
                response = logs_client.describe_log_groups(logGroupNamePrefix=log_group_prefix, nextToken=next_token)
            else:
                response = logs_client.describe_log_groups(logGroupNamePrefix=log_group_prefix)
            
            log_groups = response.get('logGroups', [])
            next_token = response.get('nextToken', None)

            # Search for any log group that contains the resource name
            for log_group in log_groups:
                log_group_name = log_group['logGroupName']
                if resource_name in log_group_name:
                    logger.info(f"Found log group: {log_group_name} for resource: {resource_name}")
                    found_log_groups.append(log_group_name)

            if not next_token:
                break  # Exit the loop if no more log groups to search

        # If we found matches, return the list; otherwise, return the default log group
        if found_log_groups:
            return found_log_groups
        else:
            logger.warning(f"No log group found for resource: {resource_name}. Using default log group.")
            return ["/aws/default-log-group"]

    except Exception as e:
        logger.error(f"Error looking up log groups for {resource_name}: {e}")
        return ["/aws/default-log-group"]

# Widget 16 and 17: Resource Summary
def create_resource_summary_widgets(resource_counts):
    widgets = []
    x, y = 0, 0
    for resource_type, count in resource_counts.items():
        widget = {
            "type": "metric",
            "x": x,
            "y": y,
            "width": 12,
            "height": 6,
            "properties": {
                "metrics": [["AWS/Service", "ResourceCount", "Service", resource_type]],
                "view": "singleValue",
                "region": "us-east-1",
                "title": f"{resource_type} Resource Count",
                "stat": "Sum",
                "period": 300  # Ensure valid period for single value metrics
            }
        }
        widgets.append(widget)
        y += 6
    return widgets

# Widget 18: Aggregate Metrics
def create_aggregate_metric_widget(metrics_data):
    widgets = []
    x, y = 0, 0
    for resource_type, metric_info in metrics_data.items():
        widget = {
            "type": "metric",
            "x": x,
            "y": y,
            "width": 24,
            "height": 6,
            "properties": {
                "metrics": metric_info['metrics'],  # Define the time series metrics
                "view": "timeSeries",  # Use time series view for historical data
                "stat": "Average",  # Default stat for time series
                "region": "us-east-1",
                "title": f"Average {metric_info['metrics'][0][1]} for {resource_type}",
                "period": 300,  # Set the time period for data aggregation
                "yAxis": {
                    "left": {
                        "min": 0  # Ensure y-axis has a minimum value
                    }
                }
            }
        }
        widgets.append(widget)
        y += 6
    return widgets

# Widget 19 and 20: Top N Resources using Log Insights
def create_top_n_widget(resource_type, metric_name, n=5):
    widget = {
        "type": "log",
        "x": 0,
        "y": 0,
        "width": 24,
        "height": 6,
        "properties": {
            "query": f"fields @timestamp, @message | filter MetricName = '{metric_name}' "
                     f"| sort @timestamp desc | limit {n}",
            "logGroupNames": [f"/aws/{resource_type.lower()}/*"],  # Ensure valid log group names
            "view": "table",  # Use table view for log query results
            "region": "us-east-1",
            "title": f"Top {n} {resource_type} Resources by {metric_name}"
        }
    }
    return widget

# Widget for Status Summary
def create_status_summary_widget(resource_counts, unhealthy_counts):
    widgets = []
    x, y = 0, 0
    for resource_type, count in resource_counts.items():
        unhealthy = unhealthy_counts.get(resource_type, 0)
        healthy = count - unhealthy
        widget = {
            "type": "metric",
            "x": x,
            "y": y,
            "width": 12,
            "height": 6,
            "properties": {
                "metrics": [["AWS/Service", "HealthyCount", "Service", resource_type],
                            ["AWS/Service", "UnhealthyCount", "Service", resource_type]],
                "view": "singleValue",  # Single value for healthy/unhealthy status
                "region": "us-east-1",
                "title": f"{resource_type} - Healthy: {healthy}, Unhealthy: {unhealthy}",
                "stat": "Sum",  # Use Sum as the aggregation type
                "period": 300  # Ensure valid period for single value metrics
            }
        }
        widgets.append(widget)
        y += 6
    return widgets

# Widget for Anomaly Detection
def create_anomaly_detection_widget(metrics_data):
    widgets = []
    x, y = 0, 0
    for resource_type, metric_info in metrics_data.items():
        widget = {
            "type": "metric",
            "x": x,
            "y": y,
            "width": 24,
            "height": 6,
            "properties": {
                "metrics": metric_info['metrics'],
                "view": "timeSeries",
                "stat": "Average",  # Default stat for anomaly detection
                "region": "us-east-1",
                "title": f"Anomaly Detection for {resource_type}",
                "period": 300,  # Ensure valid period for time series metrics
                "annotations": {
                    "horizontal": [
                        {
                            "label": "Anomaly Detection",
                            "fill": "below",
                            "color": "#ff0000",
                            "anomalyDetection": True  # Enable anomaly detection
                        }
                    ]
                },
                "yAxis": {
                    "left": {
                        "min": 0  # Ensure y-axis has a minimum value
                    }
                }
            }
        }
        widgets.append(widget)
        y += 6
    return widgets

# Main Lambda handler function
def lambda_handler(event, context):
    try:
        # Fetch all existing entries in DynamoDB
        dynamodb_entries = get_all_dynamodb_entries()

        # Initialize data structures
        resource_counts = {}
        metrics_data = {}
        logs_data = {}
        unhealthy_counts = {}

        # Process each entry in DynamoDB
        for entry in dynamodb_entries:
            try:
                resource_id = entry['ResourceID']['S']
                resource_type = entry['ResourceType']['S']
                resource_name = entry.get('ResourceName', {}).get('S', resource_id)
                metric_name = entry['MetricName']['S']
                namespace = entry['Namespace']['S']
                statistic = entry.get('Statistic', {}).get('S', "Average")
                threshold = float(entry.get('Threshold', {}).get('N', "80"))

                # Update resource counts
                resource_counts[resource_type] = resource_counts.get(resource_type, 0) + 1

                # Collect metrics for aggregate widget
                if resource_type not in metrics_data:
                    metrics_data[resource_type] = {'metrics': [], 'stat': statistic, 'threshold': threshold}
                metrics_data[resource_type]['metrics'].append([namespace, metric_name, "ResourceID", resource_id])

                # Look up log groups based on resource name
                log_group_names = lookup_log_groups(resource_name)
                if log_group_names:
                    logs_data[resource_type] = log_group_names

            except Exception as e:
                logger.error(f"Error processing DynamoDB entry: {e}")

        # Create widgets
        widgets = []
        widgets.extend(create_resource_summary_widgets(resource_counts))  # Widgets 16 & 17
        widgets.extend(create_aggregate_metric_widget(metrics_data))      # Widget 18
        widgets.append(create_top_n_widget("EC2", "CPUUtilization", 5))   # Widgets 19 & 20
        widgets.extend(create_status_summary_widget(resource_counts, unhealthy_counts))  # Status Summary
        widgets.extend(create_anomaly_detection_widget(metrics_data))     # Anomaly Detection

        # Create the dashboard body with widgets
        dashboard_body = {"widgets": widgets}

        # Create or update the CloudWatch dashboard
        cloudwatch.put_dashboard(
            DashboardName="DynamicResourceDashboard",
            DashboardBody=json.dumps(dashboard_body)
        )
        logger.info("Successfully created/updated CloudWatch dashboard.")

    except Exception as e:
        logger.error(f"Lambda execution failed: {e}")

    return {
        'statusCode': 200,
        'body': json.dumps('CloudWatch Dashboard creation and update completed successfully')
    }
