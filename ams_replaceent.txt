Write automation using AWS CDK with Python to automatically add cloudwatch alerts for resources like EC2 instances, Load balancers, RDS, and Volume upon creation.

ChatGPT
To automate the process of adding CloudWatch alarms for various AWS resources such as EC2 instances, load balancers, RDS instances, and volumes upon creation using AWS CDK with Python, you can define a CDK stack that sets up CloudWatch alarms for these resources. Below is an example implementation:

python
Copy code
from aws_cdk import (
    aws_cloudwatch as cloudwatch,
    aws_ec2 as ec2,
    aws_elasticloadbalancingv2 as elbv2,
    aws_rds as rds,
    aws_autoscaling as autoscaling,
    core
)

class CloudWatchAlarmStack(core.Stack):

    def __init__(self, scope: core.Construct, id: str, **kwargs) -> None:
        super().__init__(scope, id, **kwargs)

        # Define your VPC
        vpc = ec2.Vpc(self, "MyVpc", max_azs=2)

        # CloudWatch Alarm for EC2 instance
        instance = ec2.Instance(self, "MyInstance",
            instance_type=ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE2, ec2.InstanceSize.MICRO),
            machine_image=ec2.AmazonLinuxImage(generation=ec2.AmazonLinuxGeneration.AMAZON_LINUX_2),
            vpc=vpc
        )

        # CloudWatch Alarm for load balancer
        lb = elbv2.ApplicationLoadBalancer(self, "MyLB",
            vpc=vpc,
            internet_facing=True
        )

        listener = lb.add_listener("Listener", port=80)

        # CloudWatch Alarm for RDS instance
        db_instance = rds.DatabaseInstance(self, "MyRdsInstance",
            engine=rds.DatabaseInstanceEngine.mysql(version=rds.MysqlEngineVersion.VER_8_0),
            instance_type=ec2.InstanceType.of(ec2.InstanceClass.BURSTABLE2, ec2.InstanceSize.MICRO),
            vpc=vpc
        )

        # CloudWatch Alarm for volume
        volume = ec2.Volume(self, "MyVolume",
            availability_zone="us-west-2a",
            size=10,
            encrypted=True
        )

        # Create CloudWatch Alarms
        cloudwatch.Alarm(self, "EC2CPUAlarm",
            metric=instance.metric_cpu_utilization(),
            threshold=80,
            evaluation_periods=2,
            period=core.Duration.minutes(5),
            comparison_operator=cloudwatch.ComparisonOperator.GREATER_THAN_OR_EQUAL_TO_THRESHOLD
        )

        cloudwatch.Alarm(self, "LBRequestsAlarm",
            metric=lb.metric_http_requests(),
            threshold=1000,
            evaluation_periods=2,
            period=core.Duration.minutes(5),
            comparison_operator=cloudwatch.ComparisonOperator.GREATER_THAN_OR_EQUAL_TO_THRESHOLD
        )

        cloudwatch.Alarm(self, "RDSConnectionsAlarm",
            metric=db_instance.metric_database_connections(),
            threshold=50,
            evaluation_periods=2,
            period=core.Duration.minutes(5),
            comparison_operator=cloudwatch.ComparisonOperator.GREATER_THAN_OR_EQUAL_TO_THRESHOLD
        )

        cloudwatch.Alarm(self, "VolumeUsageAlarm",
            metric=volume.metric("VolumeUtilization"),
            threshold=90,
            evaluation_periods=2,
            period=core.Duration.minutes(5),
            comparison_operator=cloudwatch.ComparisonOperator.GREATER_THAN_OR_EQUAL_TO_THRESHOLD
        )

app = core.App()
CloudWatchAlarmStack(app, "CloudWatchAlarmStack")
app.synth()
In this CDK stack:

We define a VPC (MyVpc) to be used by the resources.
We create an EC2 instance (MyInstance), an Application Load Balancer (MyLB), an RDS instance (MyRdsInstance), and an EBS volume (MyVolume) within the VPC.
For each resource, we create a CloudWatch alarm to monitor specific metrics. For example, for the EC2 instance, we monitor CPU utilization, for the load balancer, we monitor HTTP requests, for the RDS instance, we monitor database connections, and for the volume, we monitor volume utilization.
We set thresholds and evaluation periods for each CloudWatch alarm.
You can further customize the CloudWatch alarms by adjusting the thresholds, evaluation periods, comparison operators, etc., according to your specific requirements.

Once deployed, this CDK stack will automatically create CloudWatch alarms for the specified resources whenever they are created.

User
No, the logic should automatically search for newly provisioned resources within past 1 hour and add alerts automatically.
ChatGPT
To automatically add CloudWatch alarms for newly provisioned resources within the past 1 hour, you can use CloudTrail to monitor AWS API calls and CloudWatch Events to trigger a Lambda function that adds alarms for specific resource types. Below is an outline of the approach:

Configure CloudTrail to log AWS API calls.
Create a CloudWatch Events rule to trigger a Lambda function whenever a resource creation event is detected.
Write a Lambda function that parses the CloudTrail event, identifies the newly provisioned resources within the past 1 hour, and adds CloudWatch alarms for those resources.
Here's an example Lambda function in Python:

python
Copy code
import boto3
import datetime

def lambda_handler(event, context):
    # Initialize AWS clients
    cloudwatch = boto3.client('cloudwatch')
    ec2 = boto3.client('ec2')
    elbv2 = boto3.client('elbv2')
    rds = boto3.client('rds')
    cloudtrail = boto3.client('cloudtrail')

    # Get the current time and the time 1 hour ago
    now = datetime.datetime.utcnow()
    one_hour_ago = now - datetime.timedelta(hours=1)

    # List all the CloudTrail events for the past 1 hour
    response = cloudtrail.lookup_events(
        LookupAttributes=[
            {
                'AttributeKey': 'EventTime',
                'AttributeValue': one_hour_ago.strftime('%Y-%m-%dT%H:%M:%SZ')
            }
        ]
    )

    # Identify the resource creation events and add CloudWatch alarms
    for event in response['Events']:
        event_name = event['EventName']
        resource_type = event['ResourceType']
        resource_name = event['ResourceName']

        # Check if the event is a resource creation event
        if event_name.startswith('Create') and resource_type in ['AWS::EC2::Instance', 'AWS::EC2::Volume', 'AWS::RDS::DBInstance', 'AWS::ElasticLoadBalancingV2::LoadBalancer']:
            # Add CloudWatch alarms based on resource type
            if resource_type == 'AWS::EC2::Instance':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for EC2 instance
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::EC2::Volume':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for EBS volume
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::RDS::DBInstance':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for RDS instance
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::ElasticLoadBalancingV2::LoadBalancer':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for load balancer
                    # Define your CloudWatch alarm parameters here
                )

    return {
        'statusCode': 200,
        'body': 'CloudWatch alarms added for newly provisioned resources.'
    }
Please note that you'll need to define the specific CloudWatch alarm parameters based on your requirements for each resource type.

Additionally, you'll need to set up CloudTrail and CloudWatch Events to trigger this Lambda function whenever a resource creation event occurs. The Lambda function will then automatically add CloudWatch alarms for the newly provisioned resources within the past 1 hour.

User
Can we include use of glue or dynamodb in above logic to make it more fault tolerant?
ChatGPT
Yes, you can enhance the fault tolerance of the above logic by incorporating AWS Glue or DynamoDB to maintain a record of the provisioned resources and the CloudWatch alarms associated with them. This can help in scenarios where the Lambda function fails or gets invoked multiple times for the same event, ensuring idempotency and preventing duplicate alarms.

Here's how you can modify the Lambda function to utilize DynamoDB:

Whenever a resource creation event is detected, the Lambda function checks if the resource ID already exists in DynamoDB.
If the resource ID doesn't exist, it adds CloudWatch alarms for the resource and records the resource ID in DynamoDB.
If the resource ID already exists, it skips adding alarms to prevent duplicates.
Here's a modified version of the Lambda function:

python
Copy code
import boto3
import datetime

dynamodb = boto3.resource('dynamodb')
table_name = 'ResourceAlarmTable'

def lambda_handler(event, context):
    cloudwatch = boto3.client('cloudwatch')
    cloudtrail = boto3.client('cloudtrail')

    for record in event['Records']:
        # Parse CloudTrail event
        event = json.loads(record['Sns']['Message'])
        event_name = event['detail']['eventName']
        resource_type = event['detail']['responseElements']['resourceType']
        resource_id = event['detail']['responseElements']['resourceId']
        
        # Check if resource creation event and if resource ID exists in DynamoDB
        if event_name.startswith('Create') and not is_resource_exists(resource_id):
            # Add CloudWatch alarms based on resource type
            if resource_type == 'AWS::EC2::Instance':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for EC2 instance
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::EC2::Volume':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for EBS volume
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::RDS::DBInstance':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for RDS instance
                    # Define your CloudWatch alarm parameters here
                )
            elif resource_type == 'AWS::ElasticLoadBalancingV2::LoadBalancer':
                cloudwatch.put_metric_alarm(
                    # Add CloudWatch alarm for load balancer
                    # Define your CloudWatch alarm parameters here
                )
            
            # Record resource ID in DynamoDB to prevent duplicates
            record_resource(resource_id)

    return {
        'statusCode': 200,
        'body': 'CloudWatch alarms added for newly provisioned resources.'
    }

def is_resource_exists(resource_id):
    table = dynamodb.Table(table_name)
    response = table.get_item(Key={'ResourceId': resource_id})
    return 'Item' in response

def record_resource(resource_id):
    table = dynamodb.Table(table_name)
    table.put_item(Item={'ResourceId': resource_id})
In this modified version:

The is_resource_exists() function checks if the resource ID exists in DynamoDB.
The record_resource() function records the resource ID in DynamoDB.
Before adding CloudWatch alarms for a resource, the Lambda function checks if the resource ID already exists in DynamoDB to prevent duplicates.
If the resource ID doesn't exist, it adds CloudWatch alarms and records the resource ID in DynamoDB.
Ensure that you have created a DynamoDB table named ResourceAlarmTable with a primary key ResourceId. Adjust the DynamoDB table name and key as per your setup.

User
write a logic in AWS to automatically create a Jira ticket under specific epic in case a cloudwatch alarm triggers
ChatGPT
To automatically create a Jira ticket under a specific epic when a CloudWatch alarm triggers, you can use AWS Lambda along with the AWS SDK to interact with Jira's REST API. Here's an outline of the approach:

Set up a CloudWatch alarm to monitor the metric of interest.
Create an AWS Lambda function that is triggered by the CloudWatch alarm.
Write the Lambda function to extract relevant information from the CloudWatch alarm, such as the alarm name, description, and the instance ID or resource name.
Use the Lambda function to create a Jira ticket via Jira's REST API, specifying the details extracted from the CloudWatch alarm.
Ensure the Lambda function has the necessary permissions to interact with Jira's REST API.
Test the integration to verify that Jira tickets are created when CloudWatch alarms trigger.
Below is a simplified example of how you can implement this using Python and AWS Lambda:

python
Copy code
import requests
import json
import os

def create_jira_ticket(event, context):
    # Extract relevant information from the CloudWatch alarm event
    alarm_name = event['detail']['alarmName']
    alarm_description = event['detail']['alarmDescription']
    instance_id = event['detail']['configuration']['instanceId']  # Example, modify as per your alarm configuration
    
    # Prepare Jira ticket payload
    jira_payload = {
        "fields": {
            "project": {
                "key": os.environ['JIRA_PROJECT_KEY']
            },
            "summary": f"CloudWatch Alarm Triggered: {alarm_name}",
            "description": alarm_description,
            "issuetype": {
                "name": "Task"
            },
            "customfield_10005": os.environ['JIRA_EPIC_ID'],  # Replace with your Epic ID
            "customfield_10006": instance_id  # Replace with your relevant field
        }
    }

    # Create Jira ticket
    headers = {
        "Content-Type": "application/json"
    }
    response = requests.post(
        f"https://{os.environ['JIRA_DOMAIN']}/rest/api/2/issue/",
        headers=headers,
        json=jira_payload,
        auth=(os.environ['JIRA_USERNAME'], os.environ['JIRA_API_TOKEN'])
    )

    # Check if Jira ticket creation was successful
    if response.status_code == 201:
        print("Jira ticket created successfully.")
    else:
        print(f"Failed to create Jira ticket. Status code: {response.status_code}, Response: {response.text}")

def lambda_handler(event, context):
    create_jira_ticket(event, context)
Make sure to set up environment variables in your Lambda function for Jira credentials (JIRA_USERNAME, JIRA_API_TOKEN), Jira project key (JIRA_PROJECT_KEY), Epic ID (JIRA_EPIC_ID), and Jira domain (JIRA_DOMAIN). Also, ensure that the Lambda function has permission to write to CloudWatch logs and make HTTPS requests to the Jira REST API.

This is a basic example, and you may need to modify it based on your specific use case and Jira configuration. Additionally, ensure that you handle error cases and retries appropriately for production scenarios.